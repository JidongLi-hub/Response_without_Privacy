import json
import pandas as pd
import requests
import urllib.parse
from tqdm import tqdm
from selenium import webdriver
from selenium.webdriver.common.by import By
import time
from transformers import AutoTokenizer
import numpy as np

def json_to_jsonl(json_file_path):
    """
    å°†åŒ…å«JSONå¯¹è±¡æ•°ç»„çš„JSONæ–‡ä»¶è½¬æ¢ä¸ºJSONLæ–‡ä»¶ã€‚

    :param json_file_path: è¾“å…¥çš„JSONæ–‡ä»¶è·¯å¾„ã€‚
    :param jsonl_file_path: è¾“å‡ºçš„JSONLæ–‡ä»¶è·¯å¾„ã€‚
    """
    try:
        with open(json_file_path, 'r') as json_file:
            # ä»JSONæ–‡ä»¶ä¸­åŠ è½½æ•°æ®
            data = json.load(json_file)

            # ç¡®ä¿æ•°æ®æ˜¯ä¸€ä¸ªåˆ—è¡¨
            if not isinstance(data, list):
                print("é”™è¯¯ï¼šJSONæ–‡ä»¶çš„å†…å®¹ä¸æ˜¯ä¸€ä¸ªåˆ—è¡¨ (æ•°ç»„)ã€‚")
                return

        with open(json_file_path.replace(".json",".jsonl"), 'w') as jsonl_file:
            # éå†åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªJSONå¯¹è±¡
            for entry in data:
                # å°†æ¯ä¸ªå¯¹è±¡è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å¹¶å†™å…¥æ–‡ä»¶ï¼Œç„¶åæ·»åŠ æ¢è¡Œç¬¦
                jsonl_file.write(json.dumps(entry, ensure_ascii=False) + '\n')
        
        print(f"æˆåŠŸå°† '{json_file_path}' è½¬æ¢")

    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{json_file_path}'ã€‚")
    except json.JSONDecodeError:
        print(f"é”™è¯¯ï¼šæ— æ³•è§£æ '{json_file_path}' çš„å†…å®¹ã€‚è¯·ç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONæ–‡ä»¶ã€‚")
    except Exception as e:
        print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

def extract_new_sequences_from_VM():
    # æå–é€å­—è®°å¿†æ–‡ä¸­æä¾›çš„æ–°åºåˆ—
    file_path = "./data/injection_data_url.csv"
    output_path = "./data/injection_data.csv"
    df = pd.read_csv(file_path, header=None)

    # å¯åŠ¨ Chrome
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")  # æ— ç•Œé¢æ¨¡å¼
    driver = webdriver.Chrome(options=options)
    print("Web is ready!")

    seqs = []
    for index, row in df.iterrows():
        print(f"Processing: No.{index}")
        driver.get(row[0])
        driver.refresh()  # ğŸ”¥ å¼ºåˆ¶é‡æ–°åŠ è½½ï¼Œå› ä¸º#åé¢çš„å“ˆå¸Œéƒ¨åˆ†åœ¨æµè§ˆå™¨çœ‹æ¥æ˜¯åŒä¸€ä¸ªé¡µé¢ï¼Œæ›¿æ¢åä¸ä¼šè§¦å‘é‡å¤åŠ è½½ï¼Œæ‰€ä»¥å¼ºåˆ¶åˆ·æ–°
        time.sleep(2)
        # ç­‰å¾…åŠ è½½å¹¶æå–è¾“å…¥æ¡†å†…å®¹ï¼ˆå‡è®¾è¾“å…¥æ¡†æ˜¯ <textarea>ï¼‰
        textarea = driver.find_element(By.TAG_NAME, "textarea")
        text = textarea.get_attribute("value")
        seqs.append(text)

    driver.quit()

    od = pd.DataFrame({"seqs":seqs})
    od.to_csv(
        output_path,
        header=True,
        index=False, 
        encoding="utf-8"
    )

def extract_Seqs_to_CSV(input_path="/model/fangly/mllm/ljd/Memory_or_Hallucination/data/new_WikiFactDiff1000.json"):
    dics = json.load(open(input_path, "r"))
    
    seqs = [dic["text"] for dic in dics]
    df = pd.DataFrame(
        {
            "seqs":seqs
        }
    )
    df.to_csv("data/injection_WIKI_data.csv", header=True,index=False)





if __name__ == "__main__":
    # json_to_jsonl("./new_WikiFactDiff.json")
    # extract_new_sequences_from_VM()
    extract_Seqs_to_CSV()
    